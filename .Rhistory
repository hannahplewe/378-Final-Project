dockerfile_path = Path('Dockerfile')
if dockerfile_path.exists():
dockerfile_path.rename('Dockerfile_backup')
# Now run the vetiver function
from vetiver import prepare_docker
prepare_docker(b, 'penguin_model')
import os
from pathlib import Path
# Paths to the files that need to be handled
app_file_path = Path('app.py')
dockerfile_path = Path('Dockerfile')
# Check if app.py exists and rename it
if app_file_path.exists():
app_file_path.rename('app_backup.py')
# Check if Dockerfile exists and rename it
if dockerfile_path.exists():
dockerfile_path.rename('Dockerfile_backup')
# Now run the vetiver function
from vetiver import prepare_docker
prepare_docker(b, 'penguin_model')
import os
from pathlib import Path
# Paths to the files that need to be deleted
app_file_path = Path('app.py')
dockerfile_path = Path('Dockerfile')
# Check if app.py exists and delete it
if app_file_path.exists():
app_file_path.unlink()
# Check if Dockerfile exists and delete it
if dockerfile_path.exists():
dockerfile_path.unlink()
# Now run the vetiver function
from vetiver import prepare_docker
prepare_docker(b, 'penguin_model')
library(reticulate)
use_virtualenv("~/.virtualenvs/r-reticulate", required = TRUE)
py_config()
reticulate::repl_python()
from palmerpenguins import penguins
from pandas import get_dummies
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn import preprocessing
df = penguins.load_penguins().dropna()
df.head(3)
X = get_dummies(df[['bill_length_mm', 'species', 'sex']], drop_first = True)
y = df['body_mass_g']
model = LinearRegression().fit(X, y)
X = get_dummies(df[['bill_length_mm', 'species', 'sex']], drop_first = True)
y = df['body_mass_g']
model = LinearRegression().fit(X, y)
print(f"R^2 {model.score(X,y)}")
print(f"Intercept {model.intercept_}")
print(f"Columns {X.columns}")
print(f"Coefficients {model.coef_}")
quit
library(reticulate)
# Install 'vetiver' (don't need to install everytime)
# py_install("vetiver")
reticulate::repl_python()
from vetiver import VetiverModel
v = VetiverModel(model, model_name='penguin_model', prototype_data=X)
exit
reticulate::repl_python()
from vetiver import VetiverAPI
# Create a FastAPI app from the VetiverModel
app = VetiverAPI(v, check_prototype=True)
app = VetiverAPI(v, check_prototype=True)
import os
from pathlib import Path
# Paths to the files that need to be deleted
app_file_path = Path('app.py')
dockerfile_path = Path('Dockerfile')
# Check if app.py exists and delete it
if app_file_path.exists():
app_file_path.unlink()
# Check if Dockerfile exists and delete it
if dockerfile_path.exists():
dockerfile_path.unlink()
# Now run the vetiver function
from vetiver import prepare_docker
prepare_docker(b, 'penguin_model')
quit
library(reticulate)
use_virtualenv("~/.virtualenvs/r-reticulate", required = TRUE)
py_config()
reticulate::repl_python()
from palmerpenguins import penguins
from pandas import get_dummies
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn import preprocessing
print(f"Coefficients {model.coef_}")
model = LinearRegression().fit(X, y)
print(f"Columns {X.columns}")
print(f"R^2 {model.score(X,y)}")
print(f"Intercept {model.intercept_}")
print(f"Columns {X.columns}")
print(f"Coefficients {model.coef_}")
quit
library(reticulate)
# Install 'vetiver' (don't need to install everytime)
# py_install("vetiver")
reticulate::repl_python()
from vetiver import VetiverModel
v = VetiverModel(model, model_name='penguin_model', prototype_data=X)
from vetiver import VetiverAPI
# Create a FastAPI app from the VetiverModel
app = VetiverAPI(v, check_prototype=True)
from pins import board_folder
from vetiver import vetiver_pin_write
b = board_folder('data/model', allow_pickle_read=True)
vetiver_pin_write(b,v)
app = VetiverAPI(v, check_prototype=True)
# COMMENT OUT WHEN YOU NEED TO RENDER
# app.run(port = 8080)
import duckdb
from palmerpenguins import penguins
con = duckdb.connect('my-db.duckdb')
df = penguins.load_penguins()
con.execute('CREATE TABLE penguins AS SELECT * FROM df')
con.close()
import duckdb
from palmerpenguins import penguins
con = duckdb.connect('my-db.duckdb')
df = penguins.load_penguins()
con.execute('CREATE TABLE penguins AS SELECT * FROM df')
con.close()
quit
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(ggplot2)
con <- DBI::dbConnect(
duckdb::duckdb(),
dbdir = "my-db.duckdb"
)
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(ggplot2)
con <- DBI::dbConnect(
duckdb::duckdb(),
dbdir = "my-db.duckdb"
)
install.packages(DBI)
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(ggplot2)
con <- DBI::dbConnect(
duckdb::duckdb(),
dbdir = "my-db.duckdb"
)
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(dbplyr)
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(dbplyr)
install.packages(dbplyr)
?dbplyr
??dbplyr
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(dbplyr)
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(ggplot2)
con <- DBI::dbConnect(
duckdb::duckdb(),
dbdir = "my-db.duckdb"
)
install.packages("DBI")
```{r}
install.packages("DBI")
install.packages("duckdb")
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(ggplot2)
con <- DBI::dbConnect(
duckdb::duckdb(),
dbdir = "my-db.duckdb"
)
df <- dplyr::tbl(con, "penguins")
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(ggplot2)
con <- DBI::dbConnect(
duckdb::duckdb(),
dbdir = "my-db.duckdb"
)
df <- dplyr::tbl(con, "penguins")
install.packages("tidyselect")
#| warning: false
#| message: false
library(palmerpenguins)
library(dplyr)
library(ggplot2)
con <- DBI::dbConnect(
duckdb::duckdb(),
dbdir = "my-db.duckdb"
)
df <- dplyr::tbl(con, "penguins")
#| warning: false
#| message: false
# Starting with the data frame 'df',
df %>%
# Group the data by 'species' and 'sex' columns.
group_by(species, sex) %>%
# Summarise the data across all numeric columns,
summarise(
across(
# Select columns where the data type is numeric.
where(is.numeric),
# Apply a function to each selected column: calculate the mean,
# removing NA values with na.rm = TRUE.
\(x) mean(x, na.rm = TRUE)
)
) %>%
# Convert the resulting summarised table into a nicely formatted table using knitr::kable().
knitr::kable()
#| warning: false
#| message: false
# Starting with the data frame 'df',
df %>%
# Group the data by 'species' and 'sex' columns.
group_by(species, sex) %>%
# Summarise the data across all numeric columns,
summarise(
across(
# Select columns where the data type is numeric.
where(is.numeric),
# Apply a function to each selected column: calculate the mean,
# removing NA values with na.rm = TRUE.
\(x) mean(x, na.rm = TRUE)
)
) %>%
# Convert the resulting summarised table into a nicely formatted table using knitr::kable().
knitr::kable()
#| warning: false
#| message: false
df %>%
group_by(species, sex) %>%
summarise(
across(
ends_with("mm") | ends_with("g"),
\(x) mean(x, na.rm = TRUE)
)
) %>%
dplyr::collect() %>%
knitr::kable()
DBI::dbDisconnect(con)
con = duckdb.connect('my-db.duckdb')
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
con = duckdb.connect('my-db.duckdb')
df = penguins.load_penguins()
con.execute('CREATE TABLE penguins AS SELECT * FROM df')
con.close()
quit
con = duckdb.connect('my-db.duckdb')
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
import duckdb
from palmerpenguins import penguins
import duckdb
from palmerpenguins import penguins
quit
con = duckdb.connect('my-db.duckdb')
con = duckdb.connect('my-db.duckdb')
con = duckdb.connect('my-db.duckdb')
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
quit
con = duckdb.connect('my-db.duckdb')
# Load the reticulate library
library(reticulate)
# Use the py_install function to install DuckDB
py_install("duckdb")
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
quit
con = duckdb.connect('my-db.duckdb')
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
import duckdb
from palmerpenguins import penguins
import duckdb
from palmerpenguins import penguins
quit
con = duckdb.connect('my-db.duckdb')
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
quit
library(reticulate)
py_config()
reticulate::repl_python()
import duckdb
from pandas import get_dummies
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn import preprocessing
import duckdb
from pandas import get_dummies
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn import preprocessing
import duckdb
from pandas import get_dummies
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn import preprocessing
quit
library(reticulate)
py_install("scikit-learn")
reticulate::repl_python()
import sklearn
print(sklearn.__version__)
import duckdb
from pandas import get_dummies
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn import preprocessing
con = duckdb.connect('my-db.duckdb')
df = con.execute("SELECT * FROM penguins").fetchdf().dropna()
con.close()
df.head(3)
X = get_dummies(df[['bill_length_mm', 'species', 'sex']], drop_first = True)
y = df['body_mass_g']
model = LinearRegression().fit(X, y)
quit
library(reticulate)
py_config()
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
quit
con = duckdb.connect('my-db.duckdb')
library(reticulate)
py_config()
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
quit
con = duckdb.connect('my-db.duckdb')
# Load the reticulate library
library(reticulate)
# Set the Python configuration to check the current setup
py_config()
# Optionally, specify Python executable if not automatically correct
# use_python("path/to/python", required = TRUE)
# Install necessary Python packages (if not already installed)
py_install("duckdb")
py_install("palmerpenguins")
# Check if Python packages can be loaded (you can run this in an R cell)
py_run_string("import duckdb")
reticulate::py_last_error()
library(reticulate)
use_virtualenv("C:/Users/C25Hannah.Plewe/OneDrive - afacademy.af.edu/Desktop/Personal/Documents/.virtualenvs/r-reticulate", required = TRUE)
library(reticulate)
use_virtualenv("C:/Users/C25Hannah.Plewe/OneDrive - afacademy.af.edu/Desktop/Personal/Documents/.virtualenvs/r-reticulate", required = TRUE)
library(reticulate)
py_config()
reticulate::repl_python()
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
quit
con = duckdb.connect('my-db.duckdb')
reticulate::repl_python()
import duckdb
from palmerpenguins import penguins
-m pip install duckdb
-m pip install duckdb
import duckdb
from palmerpenguins import penguins
import duckdb
from palmerpenguins import penguins
quit
con = duckdb.connect('my-db.duckdb')
con = duckdb.connect('my-db.duckdb')
# Load the duckdb package
library(duckdb)
# Connect to DuckDB
con <- duckdb::duckdb_connect('my-db.duckdb')
# Load the duckdb package
library(duckdb)
# Connect to DuckDB
con <- duckdb::dbConnect(duckdb::duckdb(), dbdir = "my-db.duckdb")
# Execute a query and fetch data as a dataframe, removing NA values
df <- duckdb::dbExecute(con, "SELECT * FROM penguins")
# Load the duckdb package
library(duckdb)
# Connect to DuckDB
con <- dbConnect(duckdb(), dbdir = "my-db.duckdb", read_only = FALSE)
# Execute a SELECT query and fetch results
result <- dbSendQuery(con, "SELECT * FROM penguins")
df <- dbFetch(result)
dbClearResult(result)  # It's important to clear the result after fetching
# Optionally remove rows with NA values using base R or dplyr
df <- na.omit(df)
# Close the connection
dbDisconnect(con)
reticulate::repl_python()
from vetiver import VetiverAPI
# Create a FastAPI app from the VetiverModel
app = VetiverAPI(v, check_prototype=True)
quit
library(reticulate)
# Install 'vetiver' (don't need to install everytime)
# py_install("vetiver")
reticulate::repl_python()
from vetiver import VetiverModel
v = VetiverModel(model, model_name='penguin_model', prototype_data=X)
quit
library(reticulate)
use_virtualenv("~/.virtualenvs/r-reticulate", required = TRUE)
library(reticulate)
use_virtualenv("~/.virtualenvs/r-reticulate", required = TRUE)
library(reticulate)
use_virtualenv("~/.virtualenvs/r-reticulate", required = TRUE)
library(reticulate)
use_virtualenv("~/.virtualenvs/r-reticulate", required = TRUE)
reticulate::repl_python()
return d
reticulate::repl_python()
return r.json().get('predict')[0]
shiny::runApp('Shiny_App')
runApp('Shiny_App')
library(reticulate)
use_virtualenv("~/.virtualenvs/r-reticulate", required = TRUE)
py_config()
reticulate::repl_python()
from palmerpenguins import penguins
from pandas import get_dummies
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn import preprocessing
df = penguins.load_penguins().dropna()
df.head(3)
X = get_dummies(df[['bill_length_mm', 'species', 'sex']], drop_first = True)
y = df['body_mass_g']
model = LinearRegression().fit(X, y)
print(f"R^2 {model.score(X,y)}")
print(f"Intercept {model.intercept_}")
print(f"Columns {X.columns}")
print(f"Coefficients {model.coef_}")
from vetiver import VetiverModel
v = VetiverModel(model, model_name='penguin_model', prototype_data=X)
from vetiver import VetiverAPI
# Create a FastAPI app from the VetiverModel
app = VetiverAPI(v, check_prototype=True)
from pins import board_folder
from vetiver import vetiver_pin_write
b = board_folder('data/model', allow_pickle_read=True)
vetiver_pin_write(b,v)
app = VetiverAPI(v, check_prototype=True)
app.run(port = 8080)
# COMMENT OUT WHEN YOU NEED TO RENDER
app.run(port = 8080)
# COMMENT OUT WHEN YOU NEED TO RENDER
app.run(port = 8080)
import duckdb
from palmerpenguins import penguins
import duckdb
from palmerpenguins import penguins
con = duckdb.connect('my-db.duckdb')
df = con.execute("SELECT * FROM penguins").fetchdf().dropna()
df.head()
con.close()
quit
runApp('Shiny_App')
runApp('Shiny_App')
runApp('Shiny_App')
reticulate::repl_python()
# COMMENT OUT WHEN YOU NEED TO RENDER
app.run(port = 8080)
quit
runApp('Shiny_App')
runApp('Shiny_App')
runApp('Shiny_App')
runApp('Shiny_App')
runApp('Shiny_App')
runApp('Shiny_App')
install.packages("quarto")
library(quarto)
quarto_render()
library(quarto)
quarto_render()
git add .
